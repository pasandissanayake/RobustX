{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# How to contribute?\n",
    "\n",
    "Here we report a simple guide with the key features of RobustX in order to implement your own (robust) counterfactual explanation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from robustx.lib.models.pytorch_models.SimpleNNModel import SimpleNNModel\n",
    "from robustx.datasets.ExampleDatasets import get_example_dataset\n",
    "from robustx.lib.tasks.ClassificationTask import ClassificationTask\n",
    "from robustx.generators.CE_methods.Wachter import Wachter\n",
    "from robustx.generators.CEGenerator import CEGenerator\n",
    "from robustx.generators.robust_CE_methods.EntropicRiskCE import EntropicRiskCE\n",
    "from robustx.lib.models.pytorch_models.EnsembleModelWrapper import EnsembleModelWrapper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of single-target models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:40:57.435679Z",
     "start_time": "2025-02-07T11:40:56.501837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.9714\n",
      "model accuracy: 0.9714\n",
      "model accuracy: 0.8857\n",
      "model accuracy: 0.9429\n",
      "model accuracy: 0.9714\n",
      "model accuracy: 0.8857\n",
      "model accuracy: 0.8571\n",
      "model accuracy: 0.8857\n",
      "model accuracy: 0.6000\n",
      "model accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dl = get_example_dataset(\"iris\")\n",
    "dl.preprocess(\n",
    "    impute_strategy_numeric='mean',  # Impute missing numeric values with mean\n",
    "    scale_method='minmax',           # Apply min-max scaling\n",
    "    encode_categorical=False         # No categorical encoding needed (since no categorical features)\n",
    ")\n",
    "\n",
    "# remove the target column from the dataset that has labels 2\n",
    "dl.data = dl.data[dl.data['target'] != 2]\n",
    "\n",
    "# Load model, note some RecourseGenerators may only work with a certain type of model,\n",
    "# e.g., MCE only works with a SimpleNNModel\n",
    "n_models = 10\n",
    "model_ensemble = [SimpleNNModel(4, [10], 2, seed=0) for _ in range(n_models)]\n",
    "\n",
    "target_column = \"target\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(dl.data.drop(columns=[target_column]), dl.data[target_column], test_size=0.35, random_state=0)\n",
    "\n",
    "\n",
    "# Train each model in the ensemble\n",
    "all_indexes = np.arange(X_train.shape[0])\n",
    "for model in model_ensemble:\n",
    "    np.random.shuffle(all_indexes)\n",
    "    sampled_indexes = all_indexes[:int(0.8 * len(all_indexes))]\n",
    "    model.train(X_train.iloc[sampled_indexes], y_train.iloc[sampled_indexes], epochs=50, batch_size=16, verbose=0)\n",
    "    print(f\"model accuracy: {model.compute_accuracy(X_test.values, y_test.values):0.4f}\")\n",
    "\n",
    "emodel = EnsembleModelWrapper(\n",
    "    model_ensemble=[simple_model._model for simple_model in model_ensemble],\n",
    "    device='cpu',\n",
    "    ensemble_type=EnsembleModelWrapper.ENSEMBLE_SINGLE_OUTPUT_SINGLE_TARGET_LIST,\n",
    "    aggregation_method=EnsembleModelWrapper.AGGREGATION_MAJORITY_VOTE\n",
    ")\n",
    "preds = emodel.predict_tensor(torch.tensor(X_test.to_numpy(), dtype=torch.float), apply_softmax=True)\n",
    "# print(f\"ensemble accuracy: {emodel.compute_accuracy(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "# Create task\n",
    "task = ClassificationTask(emodel, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:02.196196Z",
     "start_time": "2025-02-07T11:40:57.436946Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative instances shape:  (1, 4)\n",
      "Example of a prediction for a negative instance:\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222             0.625           0.067797          0.041667\n",
      "Output:  0\n",
      "Class:  0\n",
      "\n",
      "Generating counterfactual explanations using EntropicRiskCF for the first 1 negative instances:\n",
      "          0         1         2         3\n",
      "0 -0.057043  0.906059  0.347517  0.321656\n",
      "Original Output:  0\n",
      "CF Output:  1\n"
     ]
    }
   ],
   "source": [
    "# Each counterfactual explanation generator takes the task on creation, it can also take a custom distance function, but for now we will use the default one.\n",
    "\n",
    "ce_gen = EntropicRiskCE(task)\n",
    "\n",
    "\n",
    "# Get negative instances, the default column_name is always \"target\" but you can set it to the name of your dataset's target variable\n",
    "# negs = dl.get_negative_instances(neg_value=0, column_name=\"target\")\n",
    "negs = dl.data.drop(columns=['target']).head(1)\n",
    "print(\"Negative instances shape: \", negs.shape)\n",
    "print(f\"Example of a prediction for a negative instance:\\n\")\n",
    "print(negs.head(1))\n",
    "print(\"Output: \", emodel.predict(negs.head(1)).values.item())\n",
    "print(\"Class: \", int(emodel.predict(negs.head(1)).values.item() > 0.5))  # Assuming binary classification with threshold 0.5\n",
    "\n",
    "# You can generate for a set of instances stored in a DataFrame\n",
    "print(\"\\nGenerating counterfactual explanations using EntropicRiskCF for the first 1 negative instances:\")\n",
    "instance = negs.head(1)\n",
    "ce = ce_gen.generate_for_instance(\n",
    "    instance=instance,\n",
    "    target_weights=None,\n",
    "    tau=0.45,\n",
    "    max_iter=50,\n",
    "    device='cpu',\n",
    "    verbose=False\n",
    ")\n",
    "print(ce)\n",
    "print(\"Original Output: \", emodel.predict(instance).values.item())\n",
    "print(\"CF Output: \", emodel.predict(ce).values.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:03.173345Z",
     "start_time": "2025-02-07T11:41:02.196825Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All query outputs are positive?  False\n",
      "All query outputs are negative?  True\n",
      "All CF outputs are positive?  False\n"
     ]
    }
   ],
   "source": [
    "# You can also implement a method to generate CEs for all the negative instance in one shot\n",
    "ces = ce_gen.generate_for_all(\n",
    "                            target_weights=None,\n",
    "                            tau=0.8,\n",
    "                            max_iter=50,\n",
    "                            device='cpu',\n",
    "                            verbose=False\n",
    ")\n",
    "print(\"All query outputs are positive? \", np.all(emodel.predict(negs)>0.5))\n",
    "print(\"All query outputs are negative? \", np.all(emodel.predict(negs)<0.5))\n",
    "print(\"All CF outputs are positive? \", np.all(emodel.predict(ces)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-output model ensemble for multiple targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "t2",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7c257d50-c997-410e-aee5-058ff060c28b",
       "rows": [
        [
         "0",
         "0.2222222222222221",
         "0.625",
         "0.06779661016949151",
         "0.04166666666666667",
         "0",
         "1"
        ],
        [
         "1",
         "0.16666666666666674",
         "0.41666666666666674",
         "0.06779661016949151",
         "0.04166666666666667",
         "0",
         "1"
        ],
        [
         "2",
         "0.11111111111111116",
         "0.5",
         "0.05084745762711865",
         "0.04166666666666667",
         "0",
         "1"
        ],
        [
         "3",
         "0.08333333333333326",
         "0.45833333333333326",
         "0.0847457627118644",
         "0.04166666666666667",
         "0",
         "0"
        ],
        [
         "4",
         "0.19444444444444442",
         "0.6666666666666667",
         "0.06779661016949151",
         "0.04166666666666667",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0           0.222222          0.625000           0.067797          0.041667   \n",
       "1           0.166667          0.416667           0.067797          0.041667   \n",
       "2           0.111111          0.500000           0.050847          0.041667   \n",
       "3           0.083333          0.458333           0.084746          0.041667   \n",
       "4           0.194444          0.666667           0.067797          0.041667   \n",
       "\n",
       "   t1  t2  \n",
       "0   0   1  \n",
       "1   0   1  \n",
       "2   0   1  \n",
       "3   0   0  \n",
       "4   0   1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dl = get_example_dataset(\"iris\")\n",
    "dl.preprocess(\n",
    "    impute_strategy_numeric='mean',  # Impute missing numeric values with mean\n",
    "    scale_method='minmax',           # Apply min-max scaling\n",
    "    encode_categorical=False         # No categorical encoding needed (since no categorical features)\n",
    ")\n",
    "\n",
    "# remove the target column from the dataset that has labels 2\n",
    "dl.data = dl.data[dl.data['target'] != 2]\n",
    "\n",
    "dl.data[\"t1\"] = dl.data[\"target\"]\n",
    "dl.data[\"t2\"] = np.random.randint(low=0, high=2, size=len(dl.data))\n",
    "dl.data = dl.data.drop(columns=\"target\")\n",
    "target_cols = [\"t1\", \"t2\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dl.data.drop(columns=target_cols), dl.data[target_cols], test_size=0.35, random_state=0)\n",
    "\n",
    "dl.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for target t1\n",
      "model accuracy: 0.9714\n",
      "model accuracy: 0.8857\n",
      "Training for target t2\n",
      "model accuracy: 0.4857\n",
      "model accuracy: 0.5143\n",
      "ensemble accuracy: {'t1': 0.9714285714285714, 't2': 0.5142857142857142}\n"
     ]
    }
   ],
   "source": [
    "# Load model, note some RecourseGenerators may only work with a certain type of model,\n",
    "# e.g., MCE only works with a SimpleNNModel\n",
    "n_models = 2\n",
    "model_ensemble = {\n",
    "    t: [SimpleNNModel(4, [10], 2, seed=0) for _ in range(n_models)]\n",
    "    for t in target_cols\n",
    "}\n",
    "\n",
    "\n",
    "# Train each model in the ensemble\n",
    "all_indexes = np.arange(X_train.shape[0])\n",
    "for target, sub_ensemble in model_ensemble.items():\n",
    "    print(f\"Training for target {target}\")\n",
    "    for model in sub_ensemble:\n",
    "        np.random.shuffle(all_indexes)\n",
    "        sampled_indexes = all_indexes[:int(0.8 * len(all_indexes))]\n",
    "        model.train(X_train.iloc[sampled_indexes], y_train[target].iloc[sampled_indexes], epochs=50, batch_size=16, verbose=0)\n",
    "        print(f\"model accuracy: {model.compute_accuracy(X_test.values, y_test[target].values):0.4f}\")\n",
    "\n",
    "model_ensemble = {\n",
    "    t: [model._model for model in sub_ensemble] for t, sub_ensemble in model_ensemble.items()\n",
    "}\n",
    "\n",
    "emodel = EnsembleModelWrapper(\n",
    "    model_ensemble=model_ensemble,\n",
    "    device='cpu',\n",
    "    ensemble_type=EnsembleModelWrapper.ENSEMBLE_SINGLE_OUTPUT_MULTI_TARGET_DICT,\n",
    "    aggregation_method=EnsembleModelWrapper.AGGREGATION_MAJORITY_VOTE\n",
    ")\n",
    "preds = emodel.predict_tensor(torch.tensor(X_test.to_numpy(), dtype=torch.float), apply_softmax=True)\n",
    "print(f\"ensemble accuracy: {emodel.compute_accuracy(X_test, y_test)}\")\n",
    "\n",
    "\n",
    "# Create task\n",
    "task = ClassificationTask(emodel, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative instances shape:  (1, 4)\n",
      "Example of a prediction for a negative instance:\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222             0.625           0.067797          0.041667\n",
      "Output: \n",
      "    t1  t2\n",
      "0   0   0\n",
      "\n",
      "Generating counterfactual explanations using EntropicRiskCF for the first 1 negative instances:\n",
      "          0         1         2         3\n",
      "0 -0.131432  0.979998  0.424915  0.399199\n",
      "Original Output: \n",
      "    t1  t2\n",
      "0   0   0\n",
      "CF Output: \n",
      "    t1  t2\n",
      "0   1   1\n"
     ]
    }
   ],
   "source": [
    "ce_gen = EntropicRiskCE(task)\n",
    "\n",
    "\n",
    "# Get negative instances, the default column_name is always \"target\" but you can set it to the name of your dataset's target variable\n",
    "# negs = dl.get_negative_instances(neg_value=0, column_name=\"target\")\n",
    "negs = dl.data.drop(columns=target_cols).head(1)\n",
    "print(\"Negative instances shape: \", negs.shape)\n",
    "print(f\"Example of a prediction for a negative instance:\\n\")\n",
    "print(negs.head(1))\n",
    "print(\"Output: \\n\", emodel.predict(negs.head(1)))\n",
    "\n",
    "# You can generate for a set of instances stored in a DataFrame\n",
    "print(\"\\nGenerating counterfactual explanations using EntropicRiskCF for the first 1 negative instances:\")\n",
    "instance = negs.head(1)\n",
    "ce = ce_gen.generate_for_instance(\n",
    "    instance=instance,\n",
    "    target_weights=None,\n",
    "    tau=0.45,\n",
    "    max_iter=50,\n",
    "    device='cpu',\n",
    "    verbose=False\n",
    ")\n",
    "print(ce)\n",
    "print(\"Original Output: \\n\", emodel.predict(instance))\n",
    "print(\"CF Output: \\n\", emodel.predict(ce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All query outputs are positive?  False\n",
      "All query outputs are negative?  True\n",
      "All CF outputs are positive?  True\n"
     ]
    }
   ],
   "source": [
    "ces = ce_gen.generate(\n",
    "                        instances=X_test,\n",
    "                        target_weights=None,\n",
    "                        tau=0.45,\n",
    "                        max_iter=50,\n",
    "                        device='cpu',\n",
    "                        verbose=False\n",
    ")\n",
    "print(\"All query outputs are positive? \", np.all(emodel.predict(negs)>0.5))\n",
    "print(\"All query outputs are negative? \", np.all(emodel.predict(negs)<0.5))\n",
    "print(\"All CF outputs are positive? \", np.all(emodel.predict(ces)>0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smiles4robx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
