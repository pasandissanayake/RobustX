{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# How to contribute?\n",
    "\n",
    "Here we report a simple guide with the key features of RobustX in order to implement your own (robust) counterfactual explanation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from robustx.lib.models.BaseModel import BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from robustx.lib.models.pytorch_models.SimpleNNModel import SimpleNNModel\n",
    "from robustx.datasets.ExampleDatasets import get_example_dataset\n",
    "from robustx.lib.tasks.ClassificationTask import ClassificationTask\n",
    "from robustx.generators.CE_methods.Wachter import Wachter\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robustx.generators.CEGenerator import CEGenerator\n",
    "\n",
    "\n",
    "class EnsembleModelWrapper(BaseModel):\n",
    "    def __init__(self, model_ensemble: list[SimpleNNModel], aggregation_method: str = 'majority_vote'):\n",
    "        super().__init__(EnsembleModelWrapper)\n",
    "        self.model_ensemble = model_ensemble\n",
    "        self.pt_model_ensemble = [model._model for model in model_ensemble]\n",
    "        self.aggregation_method = aggregation_method\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        print(\"Training should be done on individual models in the ensemble.\")\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X_tensor = torch.Tensor(X.to_numpy()).to(device)\n",
    "        preds_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_tensor).cpu().numpy()\n",
    "                preds_ensemble.append(outputs)\n",
    "        preds_ensemble = np.array(preds_ensemble)  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            final_preds = np.round(np.mean(preds_ensemble, axis=0)) # Shape: (n_samples, n_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation method: {self.aggregation_method}\")\n",
    "        predictions = final_preds.astype(int)\n",
    "        \n",
    "        return pd.DataFrame(predictions, columns=['prediction'], index=X.index)\n",
    "    \n",
    "    def predict_single(self, X: pd.DataFrame) -> int:\n",
    "        return self.predict(X).values.item()\n",
    "    \n",
    "    def predict_ensemble_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X_tensor = torch.Tensor(X.numpy()).to(device)\n",
    "        probs_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_tensor)\n",
    "                probs_ensemble.append(outputs)\n",
    "        probs_ensemble = torch.tensor(probs_ensemble)  # Shape: (n_models, n_samples, n_classes)\n",
    "        return probs_ensemble\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_tensor = torch.Tensor(X.to_numpy())\n",
    "        probs_ensemble = self.predict_ensemble_proba_tensor(X_tensor).numpy()  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            aggregated_probs = np.mean(probs_ensemble, axis=0)\n",
    "        return pd.DataFrame(aggregated_probs, columns=[f'class_{i}' for i in range(aggregated_probs.shape[1])], index=X.index)\n",
    "        \n",
    "    def predict_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X_numpy = X.numpy()\n",
    "        probabilities = self.predict_proba(X_numpy)\n",
    "        return torch.tensor(probabilities)\n",
    "    \n",
    "    def evaluate(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        report = classification_report(y, y_pred)\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report\n",
    "        }\n",
    "    \n",
    "    def compute_accuracy(self, X_test, y_test):            \n",
    "        return self.evaluate(X_test, y_test)['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:40:57.435679Z",
     "start_time": "2025-02-07T11:40:56.501837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.6286\n",
      "model accuracy: 1.0000\n",
      "ensemble accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dl = get_example_dataset(\"iris\")\n",
    "dl.preprocess(\n",
    "    impute_strategy_numeric='mean',  # Impute missing numeric values with mean\n",
    "    scale_method='minmax',           # Apply min-max scaling\n",
    "    encode_categorical=False         # No categorical encoding needed (since no categorical features)\n",
    ")\n",
    "\n",
    "# remove the target column from the dataset that has labels 2\n",
    "dl.data = dl.data[dl.data['target'] != 2]\n",
    "\n",
    "# Load model, note some RecourseGenerators may only work with a certain type of model,\n",
    "# e.g., MCE only works with a SimpleNNModel\n",
    "n_models = 2\n",
    "model_ensemble = [SimpleNNModel(4, [10], 1, seed=0) for _ in range(n_models)]\n",
    "\n",
    "target_column = \"target\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(dl.data.drop(columns=[target_column]), dl.data[target_column], test_size=0.35, random_state=0)\n",
    "\n",
    "\n",
    "# Train each model in the ensemble\n",
    "all_indexes = np.arange(X_train.shape[0])\n",
    "for model in model_ensemble:\n",
    "    np.random.shuffle(all_indexes)\n",
    "    sampled_indexes = all_indexes[:int(0.8 * len(all_indexes))]\n",
    "    model.train(X_train.iloc[sampled_indexes], y_train.iloc[sampled_indexes], epochs=100, batch_size=16, verbose=0)\n",
    "    print(f\"model accuracy: {model.compute_accuracy(X_test.values, y_test.values):0.4f}\")\n",
    "\n",
    "emodel = EnsembleModelWrapper(model_ensemble=model_ensemble, aggregation_method='majority_vote')\n",
    "print(f\"ensemble accuracy: {emodel.compute_accuracy(X_test, y_test):0.4f}\")\n",
    "\n",
    "\n",
    "# Create task\n",
    "task = ClassificationTask(emodel, dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an already implemented CE generation method in RobustX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropicRisk(torch.nn.Module):\n",
    "    def __init__(self, theta):\n",
    "        super(EntropicRisk, self).__init__()\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, ensemble_proba):\n",
    "        # ensemble_proba contains prediction probs of each model in ensemble\n",
    "        # for the target class, shape: (n_models, batch_size)\n",
    "        exp_logits = torch.exp(1 - self.theta * ensemble_proba)  # Apply exponential and 1-theta*m(x) loss\n",
    "        avg_exp_logits = torch.mean(exp_logits, dim=0)  # Average over models, Shape: (batch_size)        \n",
    "        risk = (1 / self.theta) * torch.log(avg_exp_logits + 1e-10)  # Add small constant for numerical stability\n",
    "        return risk\n",
    "\n",
    "\n",
    "# Implement the RecourseGenerator class\n",
    "class EntropicCE(CEGenerator):\n",
    "    # You must implement the _generation_method function, this returns the CE for a given\n",
    "    # instance, if you take any extra arguments make sure to specify them before **kwargs,\n",
    "    # like we have done for n and seed (they must have some default value)\n",
    "    def _generation_method(self, \n",
    "                           instance, \n",
    "                           column_name=\"target\", \n",
    "                           neg_value=0,\n",
    "                           max_iter=10,\n",
    "                           theta=1.0,\n",
    "                           tau=0.5,\n",
    "                           lr=0.01,\n",
    "                           epsilon=0.1,\n",
    "                           seed=None, \n",
    "                           ref_model_idx=None,\n",
    "                           device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                           **kwargs):\n",
    "        # Remember, the RecourseGenerator has access to its Task! Use this to get access to your dataset or model,\n",
    "        # or to use any of their methods, here we use the ClassificationTask's get_random_positive_instance() method\n",
    "\n",
    "        model_ensemble = self.task.model.model_ensemble\n",
    "        n_models = len(model_ensemble)\n",
    "        if ref_model_idx is None:\n",
    "            ref_model_idx = np.random.randint(0, n_models)\n",
    "        \n",
    "        ref_model = model_ensemble[ref_model_idx]\n",
    "        ref_task = ClassificationTask(ref_model, self.task.training_data)\n",
    "        ce_gen = Wachter(ref_task)\n",
    "        ref_ce = ce_gen.generate_for_instance(instance, neg_value=neg_value, device=device)\n",
    "\n",
    "        ref_ce = torch.Tensor(ref_ce.to_numpy()).to(device)\n",
    "        ent_ce = torch.autograd.Variable(ref_ce.clone(), requires_grad=True).to(device)\n",
    "\n",
    "        optimiser = torch.optim.Adam([ent_ce], lr, amsgrad=True)\n",
    "        entropic_risk = EntropicRisk(theta).to(device)\n",
    "\n",
    "        iterations = 0\n",
    "        cf_is_valid = False\n",
    "        while not cf_is_valid and iterations <= max_iter:\n",
    "            optimiser.zero_grad()\n",
    "            class_prob = self.task.model.predict_ensemble_proba_tensor(ent_ce)\n",
    "            risk = entropic_risk(class_prob[:, 1-neg_value])  # Assuming binary classification, get probs for positive class\n",
    "            risk.sum().backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            # break conditions\n",
    "            if risk.item() < tau:\n",
    "                cf_is_valid = True\n",
    "            iterations += 1\n",
    "        \n",
    "        if not cf_is_valid:\n",
    "            print(\"Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\")\n",
    "\n",
    "        res = pd.DataFrame(ent_ce.detach().numpy()).T\n",
    "        res.columns = instance.index\n",
    "        \n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:02.196196Z",
     "start_time": "2025-02-07T11:40:57.436946Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative instances shape:  (50, 4)\n",
      "Example of a prediction for a negative instance:\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222             0.625           0.067797          0.041667\n",
      "Output:  0\n",
      "Class:  0\n",
      "\n",
      "Generating counterfactual explanations using STCE for the first 5 negative instances:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# You can generate for a set of instances stored in a DataFrame\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating counterfactual explanations using STCE for the first 5 negative instances:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m ce \u001b[38;5;241m=\u001b[39m \u001b[43mce_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_for_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(ce)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mpredict(ce)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/export/pasand/RobustX/robustx/generators/CEGenerator.py:66\u001b[0m, in \u001b[0;36mCEGenerator.generate_for_instance\u001b[0;34m(self, instance, neg_value, column_name, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_for_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m, instance, neg_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     55\u001b[0m                           column_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    Generates a counterfactual for a provided instance.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    @return: A DataFrame containing the counterfactual explanations for the instance.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generation_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 56\u001b[0m, in \u001b[0;36mEntropicCE._generation_method\u001b[0;34m(self, instance, column_name, neg_value, max_iter, theta, tau, lr, epsilon, seed, ref_model_idx, device, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cf_is_valid \u001b[38;5;129;01mand\u001b[39;00m iterations \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_iter:\n\u001b[1;32m     55\u001b[0m     optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 56\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_ensemble_proba_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ment_ce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     risk \u001b[38;5;241m=\u001b[39m entropic_risk(class_prob[:, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mneg_value])  \u001b[38;5;66;03m# Assuming binary classification, get probs for positive class\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     risk\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[116], line 48\u001b[0m, in \u001b[0;36mEnsembleModelWrapper.predict_ensemble_proba_tensor\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_ensemble_proba_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     47\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_model_ensemble[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 48\u001b[0m     X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     49\u001b[0m     probs_ensemble \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_model_ensemble:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Each counterfactual explanation generator takes the task on creation, it can also take a custom distance function, but for now we will use the default one.\n",
    "ce_gen = EntropicCE(task)\n",
    "\n",
    "# Get negative instances, the default column_name is always \"target\" but you can set it to the name of your dataset's target variable\n",
    "negs = dl.get_negative_instances(neg_value=0, column_name=\"target\")\n",
    "print(\"Negative instances shape: \", negs.shape)\n",
    "print(f\"Example of a prediction for a negative instance:\\n\")\n",
    "print(negs.head(1))\n",
    "print(\"Output: \", emodel.predict(negs.head(1)).values.item())\n",
    "print(\"Class: \", int(emodel.predict(negs.head(1)).values.item() > 0.5))  # Assuming binary classification with threshold 0.5\n",
    "\n",
    "# You can generate for a set of instances stored in a DataFrame\n",
    "print(\"\\nGenerating counterfactual explanations using STCE for the first 5 negative instances:\")\n",
    "ce = ce_gen.generate_for_instance(negs.iloc[0], device='cpu')\n",
    "print(ce)\n",
    "print(\"Output: \", model.predict(ce).values.item())\n",
    "print(\"Class: \", int(model.predict(ce).values.item() > 0.5))  # Assuming binary classification with threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:03.173345Z",
     "start_time": "2025-02-07T11:41:02.196825Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All outputs are positive?  True\n"
     ]
    }
   ],
   "source": [
    "# You can also implement a method to generate CEs for all the negative instance in one shot\n",
    "ces = ce_gen.generate_for_all(neg_value=0, column_name=\"target\")\n",
    "print(\"All outputs are positive? \", np.all(model.predict(ces)>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:00.582480Z",
     "start_time": "2025-02-07T11:43:00.577104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Within the CEGenerator you can access:\n",
    "\n",
    "- The Task - self.Task\n",
    "- The DatasetLoader - self.task.training_data\n",
    "- The BaseModel - self.task.model\n",
    "\n",
    "and their respective methods. If your method needs additional arguments, you can put them in the function signature\n",
    "but do NOT remove any other arguments (including **kwargs). Remember to return a DataFrame!\n",
    "\n",
    "Here is our new CE in use below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:02.681345Z",
     "start_time": "2025-02-07T11:43:00.583425Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0            0.694444          0.333333           0.644068          0.541667\n",
      "1            0.472222          0.083333           0.508475          0.375000\n",
      "2            0.694444          0.333333           0.644068          0.541667\n",
      "3            0.472222          0.083333           0.508475          0.375000\n",
      "4            0.527778          0.083333           0.593220          0.583333\n",
      "..                ...               ...                ...               ...\n",
      "91           0.694444          0.333333           0.644068          0.541667\n",
      "92           0.555556          0.125000           0.576271          0.500000\n",
      "93           0.694444          0.333333           0.644068          0.541667\n",
      "94           0.472222          0.083333           0.508475          0.375000\n",
      "95           0.555556          0.125000           0.576271          0.500000\n",
      "\n",
      "[96 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create RecourseGenerator\n",
    "random_ce = RandomCE(task)\n",
    "\n",
    "# Test it\n",
    "ces = random_ce.generate_for_all()\n",
    "print(ces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can verify it by seeing all the predictions for the CEs are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:02.684474Z",
     "start_time": "2025-02-07T11:43:02.682067Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0   0.501608\n",
      "1   0.505629\n",
      "2   0.501608\n",
      "3   0.505629\n",
      "4   0.502795\n",
      "..       ...\n",
      "91  0.501608\n",
      "92  0.505989\n",
      "93  0.501608\n",
      "94  0.505629\n",
      "95  0.505989\n",
      "\n",
      "[96 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(ces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking your method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished implementing your method, you can include it into DefaultBenchmark.py file and test it against other methods supported in the library using this lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+------------+------------+\n",
      "| Method     |   Execution Time (s) |   Validity |   Distance |\n",
      "+============+======================+============+============+\n",
      "| KDTreeNNCE |            0.0493832 |          1 |   0.533264 |\n",
      "+------------+----------------------+------------+------------+\n",
      "| MCER       |            0.938715  |          1 |   0.407967 |\n",
      "+------------+----------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from robustx.lib.DefaultBenchmark import default_benchmark\n",
    "methods = [\"KDTreeNNCE\", \"MCER\"]\n",
    "evaluations = [\"Validity\", \"Distance\"]\n",
    "default_benchmark(task, methods, evaluations, neg_value=0, column_name=\"target\", delta=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
