{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# How to contribute?\n",
    "\n",
    "Here we report a simple guide with the key features of RobustX in order to implement your own (robust) counterfactual explanation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from robustx.lib.models.BaseModel import BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from robustx.lib.models.pytorch_models.SimpleNNModel import SimpleNNModel\n",
    "from robustx.datasets.ExampleDatasets import get_example_dataset\n",
    "from robustx.lib.tasks.ClassificationTask import ClassificationTask\n",
    "from robustx.generators.CE_methods.Wachter import Wachter\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robustx.generators.CEGenerator import CEGenerator\n",
    "from robustx.generators.robust_CE_methods.EntropicRiskCE import EntropicRiskCE\n",
    "\n",
    "\n",
    "class EnsembleModelWrapper(BaseModel):\n",
    "    def __init__(self, model_ensemble: list[SimpleNNModel], aggregation_method: str = 'majority_vote'):\n",
    "        super().__init__(EnsembleModelWrapper)\n",
    "        self.model_ensemble = model_ensemble\n",
    "        self.pt_model_ensemble = [model._model for model in model_ensemble]\n",
    "        self.aggregation_method = aggregation_method\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        print(\"Training should be done on individual models in the ensemble.\")\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X_tensor = torch.Tensor(X.to_numpy()).to(device)\n",
    "        preds_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_tensor).cpu().numpy()\n",
    "                preds_ensemble.append(outputs)\n",
    "        preds_ensemble = np.array(preds_ensemble)  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            final_preds = np.round(np.mean(preds_ensemble, axis=0)) # Shape: (n_samples, n_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation method: {self.aggregation_method}\")\n",
    "        predictions = final_preds.astype(int)\n",
    "        \n",
    "        return pd.DataFrame(predictions, columns=['prediction'], index=X.index)\n",
    "    \n",
    "    def predict_single(self, X: pd.DataFrame) -> int:\n",
    "        return self.predict(X).values.item()\n",
    "    \n",
    "    def predict_ensemble_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X = X.to(device)\n",
    "        probs_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            outputs = model(X)\n",
    "            probs_ensemble.append(outputs)\n",
    "        probs_ensemble = torch.stack(probs_ensemble, dim=0)  # Shape: (n_models, n_samples, n_classes)\n",
    "        return probs_ensemble\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_tensor = torch.Tensor(X.to_numpy())\n",
    "        probs_ensemble = self.predict_ensemble_proba_tensor(X_tensor).numpy()  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            aggregated_probs = np.mean(probs_ensemble, axis=0)\n",
    "        return pd.DataFrame(aggregated_probs, columns=[f'class_{i}' for i in range(aggregated_probs.shape[1])], index=X.index)\n",
    "        \n",
    "    def predict_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X_numpy = X.numpy()\n",
    "        probabilities = self.predict_proba(X_numpy)\n",
    "        return torch.tensor(probabilities)\n",
    "    \n",
    "    def evaluate(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        report = classification_report(y, y_pred)\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report\n",
    "        }\n",
    "    \n",
    "    def compute_accuracy(self, X_test, y_test):            \n",
    "        return self.evaluate(X_test, y_test)['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:40:57.435679Z",
     "start_time": "2025-02-07T11:40:56.501837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.5143\n",
      "model accuracy: 1.0000\n",
      "model accuracy: 0.6000\n",
      "model accuracy: 0.5143\n",
      "model accuracy: 1.0000\n",
      "model accuracy: 0.4286\n",
      "model accuracy: 0.4286\n",
      "model accuracy: 0.5143\n",
      "model accuracy: 0.5714\n",
      "model accuracy: 0.4571\n",
      "ensemble accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dl = get_example_dataset(\"iris\")\n",
    "dl.preprocess(\n",
    "    impute_strategy_numeric='mean',  # Impute missing numeric values with mean\n",
    "    scale_method='minmax',           # Apply min-max scaling\n",
    "    encode_categorical=False         # No categorical encoding needed (since no categorical features)\n",
    ")\n",
    "\n",
    "# remove the target column from the dataset that has labels 2\n",
    "dl.data = dl.data[dl.data['target'] != 2]\n",
    "\n",
    "# Load model, note some RecourseGenerators may only work with a certain type of model,\n",
    "# e.g., MCE only works with a SimpleNNModel\n",
    "n_models = 10\n",
    "model_ensemble = [SimpleNNModel(4, [10], 1, seed=0) for _ in range(n_models)]\n",
    "\n",
    "target_column = \"target\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(dl.data.drop(columns=[target_column]), dl.data[target_column], test_size=0.35, random_state=0)\n",
    "\n",
    "\n",
    "# Train each model in the ensemble\n",
    "all_indexes = np.arange(X_train.shape[0])\n",
    "for model in model_ensemble:\n",
    "    np.random.shuffle(all_indexes)\n",
    "    sampled_indexes = all_indexes[:int(0.8 * len(all_indexes))]\n",
    "    model.train(X_train.iloc[sampled_indexes], y_train.iloc[sampled_indexes], epochs=100, batch_size=16, verbose=0)\n",
    "    print(f\"model accuracy: {model.compute_accuracy(X_test.values, y_test.values):0.4f}\")\n",
    "\n",
    "emodel = EnsembleModelWrapper(model_ensemble=model_ensemble, aggregation_method='majority_vote')\n",
    "print(f\"ensemble accuracy: {emodel.compute_accuracy(X_test, y_test):0.4f}\")\n",
    "\n",
    "\n",
    "# Create task\n",
    "task = ClassificationTask(emodel, dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an already implemented CE generation method in RobustX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:02.196196Z",
     "start_time": "2025-02-07T11:40:57.436946Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative instances shape:  (50, 4)\n",
      "Example of a prediction for a negative instance:\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222             0.625           0.067797          0.041667\n",
      "Output:  0\n",
      "Class:  0\n",
      "\n",
      "Generating counterfactual explanations using STCE for the first 5 negative instances:\n",
      "Iteration 01: Entropic risk = 0.4783\n",
      "Current CE: [[ 0.48739973  0.3623934   0.32340688 -0.22069548]]\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0             0.4874          0.362393           0.323407         -0.220695\n",
      "Output:  0.5105839967727661\n",
      "Class:  1\n"
     ]
    }
   ],
   "source": [
    "# Each counterfactual explanation generator takes the task on creation, it can also take a custom distance function, but for now we will use the default one.\n",
    "ce_gen = EntropicRiskCE(task)\n",
    "base_cf_gen_class = Wachter\n",
    "base_cf_gen_args = {\n",
    "    'target_class': 1,\n",
    "    'max_iter': 100,\n",
    "    'lr': 0.01,\n",
    "    'lambda_param': 0.1,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "\n",
    "# Get negative instances, the default column_name is always \"target\" but you can set it to the name of your dataset's target variable\n",
    "negs = dl.get_negative_instances(neg_value=0, column_name=\"target\")\n",
    "print(\"Negative instances shape: \", negs.shape)\n",
    "print(f\"Example of a prediction for a negative instance:\\n\")\n",
    "print(negs.head(1))\n",
    "print(\"Output: \", emodel.predict(negs.head(1)).values.item())\n",
    "print(\"Class: \", int(emodel.predict(negs.head(1)).values.item() > 0.5))  # Assuming binary classification with threshold 0.5\n",
    "\n",
    "# You can generate for a set of instances stored in a DataFrame\n",
    "print(\"\\nGenerating counterfactual explanations using STCE for the first 5 negative instances:\")\n",
    "ce = ce_gen.generate_for_instance(negs.iloc[0],\n",
    "                                  base_cf_gen_class=base_cf_gen_class,\n",
    "                                  base_cf_gen_args=base_cf_gen_args,\n",
    "                                  verbose=True, \n",
    "                                  device='cpu')\n",
    "print(ce)\n",
    "print(\"Output: \", model.predict(ce).values.item())\n",
    "print(\"Class: \", int(model.predict(ce).values.item() > 0.5))  # Assuming binary classification with threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:03.173345Z",
     "start_time": "2025-02-07T11:41:02.196825Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\n",
      "All outputs are positive?  False\n"
     ]
    }
   ],
   "source": [
    "# You can also implement a method to generate CEs for all the negative instance in one shot\n",
    "ces = ce_gen.generate_for_all(neg_value=0, \n",
    "                              column_name=\"target\", \n",
    "                              base_cf_gen_class=base_cf_gen_class, \n",
    "                              base_cf_gen_args=base_cf_gen_args, \n",
    "                              device='cpu')\n",
    "print(\"All outputs are positive? \", np.all(model.predict(ces)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking your method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished implementing your method, you can include it into DefaultBenchmark.py file and test it against other methods supported in the library using this lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+------------+------------+\n",
      "| Method         |   Execution Time (s) |   Validity |   Distance |\n",
      "+================+======================+============+============+\n",
      "| KDTreeNNCE     |             0.147826 |   1        |   0.447422 |\n",
      "+----------------+----------------------+------------+------------+\n",
      "| EntropicRiskCE |             0.654669 |   0.617284 |   0.270493 |\n",
      "+----------------+----------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from robustx.lib.DefaultBenchmark import default_benchmark\n",
    "methods = [\"KDTreeNNCE\", \"EntropicRiskCE\"]\n",
    "evaluations = [\"Validity\", \"Distance\"]\n",
    "default_benchmark(task, methods, evaluations, \n",
    "                  neg_value=0, \n",
    "                  column_name=\"target\", \n",
    "                  delta=0.005,\n",
    "                  base_cf_gen_class=base_cf_gen_class,\n",
    "                  base_cf_gen_args=base_cf_gen_args,\n",
    "                  tau=0.8,\n",
    "                  device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
