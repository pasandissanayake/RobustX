{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# How to contribute?\n",
    "\n",
    "Here we report a simple guide with the key features of RobustX in order to implement your own (robust) counterfactual explanation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from robustx.lib.models.BaseModel import BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from robustx.lib.models.pytorch_models.SimpleNNModel import SimpleNNModel\n",
    "from robustx.datasets.ExampleDatasets import get_example_dataset\n",
    "from robustx.lib.tasks.ClassificationTask import ClassificationTask\n",
    "from robustx.generators.CE_methods.Wachter import Wachter\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robustx.generators.CEGenerator import CEGenerator\n",
    "\n",
    "\n",
    "class EnsembleModelWrapper(BaseModel):\n",
    "    def __init__(self, model_ensemble: list[torch.nn.Module], aggregation_method: str = 'majority_vote'):\n",
    "        super().__init__(EnsembleModelWrapper)\n",
    "        self.model_ensemble = model_ensemble\n",
    "        self.pt_model_ensemble = [model._model for model in model_ensemble]\n",
    "        self.aggregation_method = aggregation_method\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        print(\"Training should be done on individual models in the ensemble.\")\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X_tensor = torch.Tensor(X.to_numpy()).to(device)\n",
    "        preds_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_tensor).cpu().numpy()\n",
    "                preds_ensemble.append(outputs)\n",
    "        preds_ensemble = np.array(preds_ensemble)  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            final_preds = np.squeeze(np.round(np.mean(preds_ensemble, axis=0)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation method: {self.aggregation_method}\")\n",
    "        predictions = final_preds.astype(int)\n",
    "        return pd.DataFrame(predictions, columns=['prediction'], index=X.index)\n",
    "    \n",
    "    def predict_single(self, X: pd.DataFrame) -> int:\n",
    "        return self.predict(X).values.item()\n",
    "    \n",
    "    def predict_ensemble_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        device = next(self.pt_model_ensemble[0].parameters()).device\n",
    "        X_tensor = torch.Tensor(X.to_numpy()).to(device)\n",
    "        probs_ensemble = []\n",
    "        for model in self.pt_model_ensemble:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_tensor)\n",
    "                probs_ensemble.append(outputs)\n",
    "        probs_ensemble = torch.tensor(probs_ensemble)  # Shape: (n_models, n_samples, n_classes)\n",
    "        return probs_ensemble\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_tensor = torch.Tensor(X.to_numpy())\n",
    "        probs_ensemble = self.predict_ensemble_proba_tensor(X_tensor).numpy()  # Shape: (n_models, n_samples, n_classes)\n",
    "        if self.aggregation_method == 'majority_vote':\n",
    "            aggregated_probs = np.mean(probs_ensemble, axis=0)\n",
    "        return pd.DataFrame(aggregated_probs, columns=[f'class_{i}' for i in range(aggregated_probs.shape[1])], index=X.index)\n",
    "        \n",
    "    def predict_proba_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X_numpy = X.numpy()\n",
    "        probabilities = self.predict_proba(X_numpy)\n",
    "        return torch.tensor(probabilities)\n",
    "    \n",
    "    def evaluate(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        report = classification_report(y, y_pred)\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report\n",
    "        }\n",
    "    \n",
    "    def compute_accuracy(self, X_test, y_test):            \n",
    "        return self.evaluate(X_test, y_test)['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:40:57.435679Z",
     "start_time": "2025-02-07T11:40:56.501837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.5143\n",
      "model accuracy: 1.0000\n",
      "ensemble accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dl = get_example_dataset(\"iris\")\n",
    "dl.preprocess(\n",
    "    impute_strategy_numeric='mean',  # Impute missing numeric values with mean\n",
    "    scale_method='minmax',           # Apply min-max scaling\n",
    "    encode_categorical=False         # No categorical encoding needed (since no categorical features)\n",
    ")\n",
    "\n",
    "# remove the target column from the dataset that has labels 2\n",
    "dl.data = dl.data[dl.data['target'] != 2]\n",
    "\n",
    "# Load model, note some RecourseGenerators may only work with a certain type of model,\n",
    "# e.g., MCE only works with a SimpleNNModel\n",
    "n_models = 2\n",
    "model_ensemble = [SimpleNNModel(4, [10], 1, seed=0) for _ in range(n_models)]\n",
    "\n",
    "target_column = \"target\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(dl.data.drop(columns=[target_column]), dl.data[target_column], test_size=0.35, random_state=0)\n",
    "\n",
    "\n",
    "# Train each model in the ensemble\n",
    "all_indexes = np.arange(X_train.shape[0])\n",
    "for model in model_ensemble:\n",
    "    np.random.shuffle(all_indexes)\n",
    "    sampled_indexes = all_indexes[:int(0.8 * len(all_indexes))]\n",
    "    model.train(X_train.iloc[sampled_indexes], y_train.iloc[sampled_indexes], epochs=100, batch_size=16, verbose=0)\n",
    "    print(f\"model accuracy: {model.compute_accuracy(X_test.values, y_test.values):0.4f}\")\n",
    "\n",
    "emodel = EnsembleModelWrapper(model_ensemble=model_ensemble, aggregation_method='majority_vote')\n",
    "print(f\"ensemble accuracy: {emodel.compute_accuracy(X_test, y_test):0.4f}\")\n",
    "\n",
    "\n",
    "# Create task\n",
    "task = ClassificationTask(emodel.model_ensemble[0], dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an already implemented CE generation method in RobustX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropicRisk(torch.nn.Module):\n",
    "    def __init__(self, theta):\n",
    "        super(EntropicRisk, self).__init__()\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, ensemble_proba):\n",
    "        # ensemble_proba contains prediction probs of each model in ensemble\n",
    "        # for the target class, shape: (n_models, batch_size)\n",
    "        exp_logits = torch.exp(1 - self.theta * ensemble_proba)  # Apply exponential and 1-theta*m(x) loss\n",
    "        avg_exp_logits = torch.mean(exp_logits, dim=0)  # Average over models, Shape: (batch_size)        \n",
    "        risk = (1 / self.theta) * torch.log(avg_exp_logits + 1e-10)  # Add small constant for numerical stability\n",
    "        return risk\n",
    "\n",
    "\n",
    "# Implement the RecourseGenerator class\n",
    "class EntropicCE(CEGenerator):\n",
    "    # You must implement the _generation_method function, this returns the CE for a given\n",
    "    # instance, if you take any extra arguments make sure to specify them before **kwargs,\n",
    "    # like we have done for n and seed (they must have some default value)\n",
    "    def _generation_method(self, \n",
    "                           instance, \n",
    "                           column_name=\"target\", \n",
    "                           neg_value=0,\n",
    "                           max_iter=10,\n",
    "                           theta=1.0,\n",
    "                           tau=0.5,\n",
    "                           lr=0.01,\n",
    "                           epsilon=0.1,\n",
    "                           seed=None, \n",
    "                           ref_model_idx=None,\n",
    "                           device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                           **kwargs):\n",
    "        # Remember, the RecourseGenerator has access to its Task! Use this to get access to your dataset or model,\n",
    "        # or to use any of their methods, here we use the ClassificationTask's get_random_positive_instance() method\n",
    "\n",
    "        model_ensemble = self.task.model.model_ensemble\n",
    "        n_models = len(model_ensemble)\n",
    "        if ref_model_idx is None:\n",
    "            ref_model_idx = np.random.randint(0, n_models, random_state=seed)\n",
    "        \n",
    "        ref_model = model_ensemble[ref_model_idx]\n",
    "        ref_task = ClassificationTask(ref_model, self.task.dataset)\n",
    "        ce_gen = Wachter(self.task)\n",
    "        ref_ce = ce_gen.generate_for_instance(instance, neg_value=neg_value, device=device)\n",
    "\n",
    "        ref_ce = torch.Tensor(ref_ce.to_numpy()).to(device)\n",
    "        ent_ce = torch.nn.Variable(ref_ce.clone(), requires_grad=True).to(device)\n",
    "\n",
    "        optimiser = torch.optim.Adam([ent_ce], lr, amsgrad=True)\n",
    "        entropic_risk = EntropicRisk(theta).to(device)\n",
    "\n",
    "        iterations = 0\n",
    "        cf_is_valid = False\n",
    "        while not cf_is_valid and iterations <= max_iter:\n",
    "            optimiser.zero_grad()\n",
    "            class_prob = self.task.model.predict_ensemble_proba_tensor(ent_ce)\n",
    "            risk = entropic_risk(class_prob[:, 1-neg_value])  # Assuming binary classification, get probs for positive class\n",
    "            risk.sum().backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            # break conditions\n",
    "            if risk.item() < tau:\n",
    "                cf_is_valid = True\n",
    "            iterations += 1\n",
    "        \n",
    "        if not cf_is_valid:\n",
    "            print(\"Warning: Entropic CE generation did not converge to a valid counterfactual within the max iterations.\")\n",
    "\n",
    "        res = pd.DataFrame(ent_ce.detach().numpy()).T\n",
    "        res.columns = instance.index\n",
    "        \n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:02.196196Z",
     "start_time": "2025-02-07T11:40:57.436946Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative instances shape:  (50, 4)\n",
      "Example of a prediction for a negative instance:\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222             0.625           0.067797          0.041667\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample of a prediction for a negative instance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(negs\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43memodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m(emodel\u001b[38;5;241m.\u001b[39mpredict(negs\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m))  \u001b[38;5;66;03m# Assuming binary classification with threshold 0.5\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# You can generate for a set of instances stored in a DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 40\u001b[0m, in \u001b[0;36mEnsembleModelWrapper.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown aggregation method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregation_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m final_preds\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/robustx/lib/python3.9/site-packages/pandas/core/frame.py:831\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    820\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    821\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    822\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    829\u001b[0m         )\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 831\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/miniconda3/envs/robustx/lib/python3.9/site-packages/pandas/core/internals/construction.py:314\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values)\n\u001b[0;32m--> 314\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
      "File \u001b[0;32m~/miniconda3/envs/robustx/lib/python3.9/site-packages/pandas/core/internals/construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=()"
     ]
    }
   ],
   "source": [
    "# Each counterfactual explanation generator takes the task on creation, it can also take a custom distance function, but for now we will use the default one.\n",
    "ce_gen = EntropicCE(task)\n",
    "\n",
    "# Get negative instances, the default column_name is always \"target\" but you can set it to the name of your dataset's target variable\n",
    "negs = dl.get_negative_instances(neg_value=0, column_name=\"target\")\n",
    "print(\"Negative instances shape: \", negs.shape)\n",
    "print(f\"Example of a prediction for a negative instance:\\n\")\n",
    "print(negs.head(1))\n",
    "print(\"Output: \", emodel.predict(negs.head(1)).values.item())\n",
    "print(\"Class: \", int(emodel.predict(negs.head(1)).values.item() > 0.5))  # Assuming binary classification with threshold 0.5\n",
    "\n",
    "# You can generate for a set of instances stored in a DataFrame\n",
    "print(\"\\nGenerating counterfactual explanations using STCE for the first 5 negative instances:\")\n",
    "ce = ce_gen.generate_for_instance(negs.iloc[0], device='cpu')\n",
    "print(ce)\n",
    "print(\"Output: \", model.predict(ce).values.item())\n",
    "print(\"Class: \", int(model.predict(ce).values.item() > 0.5))  # Assuming binary classification with threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:41:03.173345Z",
     "start_time": "2025-02-07T11:41:02.196825Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All outputs are positive?  True\n"
     ]
    }
   ],
   "source": [
    "# You can also implement a method to generate CEs for all the negative instance in one shot\n",
    "ces = ce_gen.generate_for_all(neg_value=0, column_name=\"target\")\n",
    "print(\"All outputs are positive? \", np.all(model.predict(ces)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementing your own CE Generator\n",
    "\n",
    "Here is an example of creating your own RecourseGenerator. Let's make a simple one which gets\n",
    "n different positive instances and chooses a random one. Let's say it also allows a random seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:00.582480Z",
     "start_time": "2025-02-07T11:43:00.577104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Within the CEGenerator you can access:\n",
    "\n",
    "- The Task - self.Task\n",
    "- The DatasetLoader - self.task.training_data\n",
    "- The BaseModel - self.task.model\n",
    "\n",
    "and their respective methods. If your method needs additional arguments, you can put them in the function signature\n",
    "but do NOT remove any other arguments (including **kwargs). Remember to return a DataFrame!\n",
    "\n",
    "Here is our new CE in use below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:02.681345Z",
     "start_time": "2025-02-07T11:43:00.583425Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0            0.694444          0.333333           0.644068          0.541667\n",
      "1            0.472222          0.083333           0.508475          0.375000\n",
      "2            0.694444          0.333333           0.644068          0.541667\n",
      "3            0.472222          0.083333           0.508475          0.375000\n",
      "4            0.527778          0.083333           0.593220          0.583333\n",
      "..                ...               ...                ...               ...\n",
      "91           0.694444          0.333333           0.644068          0.541667\n",
      "92           0.555556          0.125000           0.576271          0.500000\n",
      "93           0.694444          0.333333           0.644068          0.541667\n",
      "94           0.472222          0.083333           0.508475          0.375000\n",
      "95           0.555556          0.125000           0.576271          0.500000\n",
      "\n",
      "[96 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create RecourseGenerator\n",
    "random_ce = RandomCE(task)\n",
    "\n",
    "# Test it\n",
    "ces = random_ce.generate_for_all()\n",
    "print(ces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can verify it by seeing all the predictions for the CEs are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T11:43:02.684474Z",
     "start_time": "2025-02-07T11:43:02.682067Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0   0.501608\n",
      "1   0.505629\n",
      "2   0.501608\n",
      "3   0.505629\n",
      "4   0.502795\n",
      "..       ...\n",
      "91  0.501608\n",
      "92  0.505989\n",
      "93  0.501608\n",
      "94  0.505629\n",
      "95  0.505989\n",
      "\n",
      "[96 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(ces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking your method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished implementing your method, you can include it into DefaultBenchmark.py file and test it against other methods supported in the library using this lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+------------+------------+\n",
      "| Method     |   Execution Time (s) |   Validity |   Distance |\n",
      "+============+======================+============+============+\n",
      "| KDTreeNNCE |            0.0493832 |          1 |   0.533264 |\n",
      "+------------+----------------------+------------+------------+\n",
      "| MCER       |            0.938715  |          1 |   0.407967 |\n",
      "+------------+----------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from robustx.lib.DefaultBenchmark import default_benchmark\n",
    "methods = [\"KDTreeNNCE\", \"MCER\"]\n",
    "evaluations = [\"Validity\", \"Distance\"]\n",
    "default_benchmark(task, methods, evaluations, neg_value=0, column_name=\"target\", delta=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
